{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate_policy, str2bool, Actor, Q_Critic, ReplayBuffer, test_policy\n",
    "from datetime import datetime\n",
    "import gymnasium as gym\n",
    "import os, shutil\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "from torch.distributions import Beta,Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    # 创建命令行参数解析器\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # 添加各种命令行参数\n",
    "    parser.add_argument('--algo_name',default='DDPO',type=str,help=\"算法名\")\n",
    "    parser.add_argument('--dvc', type=str, default='cuda', help='运行设备: cuda 或 cpu')\n",
    "    parser.add_argument('--env_name', type=str, default='InvertedDoublePendulum-v4', help='环境名')\n",
    "    parser.add_argument('--render_mode', type=str, default='rgb_array', help='环境渲染模式')\n",
    "    parser.add_argument('--write', type=str2bool, default=True, help='使用SummaryWriter记录训练')\n",
    "    parser.add_argument('--render', type=str2bool, default=False, help='是否渲染')\n",
    "    parser.add_argument('--Loadmodel', type=str2bool, default=False, help='是否加载预训练模型')\n",
    "    parser.add_argument('--ModelIdex', type=int, default=2350000, help='要加载的模型索引')\n",
    "    parser.add_argument('--deque_maxlen',default=20,type=int)\n",
    "\n",
    "    parser.add_argument('--seed', type=int, default=1, help='随机种子')\n",
    "    parser.add_argument('--Max_train_steps', type=int, default=5e7, help='最大训练步数')\n",
    "    parser.add_argument('--save_interval', type=int, default=5e4, help='模型保存间隔，以步为单位')\n",
    "    parser.add_argument('--eval_interval', type=int, default=2e3, help='模型评估间隔，以步为单位')\n",
    "    parser.add_argument('--test_interval', type=int, default=5e4, help='视频保存间隔，以步为单位')\n",
    "\n",
    "    parser.add_argument('--gamma', type=float, default=0.99, help='折扣因子')\n",
    "    parser.add_argument('--net_width', type=int, default=256, help='隐藏网络宽度')\n",
    "    parser.add_argument('--a_lr', type=float, default=1e-3, help='Learning rate of actor')\n",
    "    parser.add_argument('--c_lr', type=float, default=1e-3, help='Learning rate of critic')\n",
    "    parser.add_argument('--batch_size', type=int, default=128, help='切片轨迹的长度')\n",
    "    parser.add_argument('--random_steps', type=int, default=5e4, help='random steps before trianing')\n",
    "    parser.add_argument('--noise', type=float, default=0.1, help='exploring noise')\n",
    "    parser.add_argument('--tau', type=float, default=0.005, help='soft update tau')\n",
    "    \n",
    "    # 解析命令行参数\n",
    "    args = parser.parse_args([])\n",
    "    args = {**vars(args)}  # 转换成字典类型    \n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_args(args):\n",
    "    ## 打印超参数\n",
    "    print(\"超参数\")\n",
    "    print(''.join(['=']*80))\n",
    "    tplt = \"{:^20}\\t{:^20}\\t{:^20}\"\n",
    "    print(tplt.format(\"Name\", \"Value\", \"Type\"))\n",
    "    for k,v in args.items():\n",
    "        print(tplt.format(k,v,str(type(v))))   \n",
    "    print(''.join(['=']*80))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_seed(env, seed):\n",
    "    \"\"\"\n",
    "    设置随机种子以确保实验的可重复性\n",
    "\n",
    "    参数:\n",
    "    - env: Gym 环境，用于训练模型\n",
    "    - seed: 随机种子值\n",
    "\n",
    "    说明:\n",
    "    1. 使用给定的随机种子设置 NumPy、Python、PyTorch 和 CUDA 的随机生成器。\n",
    "    2. 禁用 CUDA 的非确定性操作以确保实验结果的一致性。\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)  # 设置 NumPy 随机种子\n",
    "    random.seed(seed)  # 设置 Python 随机种子\n",
    "    torch.manual_seed(seed)  # 设置 PyTorch 随机种子\n",
    "    torch.cuda.manual_seed(seed)  # 设置 PyTorch CUDA 随机种子\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 设置 Python Hash 随机种子\n",
    "    torch.backends.cudnn.deterministic = True  # 禁用 CUDA 非确定性操作以确保实验结果的一致性\n",
    "    torch.backends.cudnn.benchmark = False  # 禁用 CUDA 非确定性操作以确保实验结果的一致性\n",
    "    torch.backends.cudnn.enabled = False  # 禁用 CUDA 非确定性操作以确保实验结果的一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG_agent():\n",
    "    def __init__(self, kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.actor = Actor(self.state_dim, self.action_dim, self.net_width, self.max_action).to(self.dvc)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=self.a_lr)\n",
    "        self.actor_target = copy.deepcopy(self.actor)\n",
    "\n",
    "        self.q_critic = Q_Critic(self.state_dim, self.action_dim, self.net_width).to(self.dvc)\n",
    "        self.q_critic_optimizer = torch.optim.Adam(self.q_critic.parameters(), lr=self.c_lr)\n",
    "        self.q_critic_target = copy.deepcopy(self.q_critic)\n",
    "\n",
    "        self.replay_buffer = ReplayBuffer(self.state_dim, self.action_dim, max_size=int(5e5), dvc=self.dvc)\n",
    "\n",
    "    def select_action(self, state, deterministic):\n",
    "        \"\"\"\n",
    "        选择动作\n",
    "\n",
    "        参数:\n",
    "        - state: 当前状态\n",
    "        - deterministic: 是否使用确定性策略选择动作\n",
    "\n",
    "        返回:\n",
    "        - 动作\n",
    "\n",
    "        说明:\n",
    "        1. 将状态从 [x, x, ..., x] 转换为 [[x, x, ..., x]]。\n",
    "        2. 通过 Actor 网络获取动作。\n",
    "        3. 如果是确定性策略，则直接返回动作。\n",
    "        4. 如果是非确定性策略，则添加噪声并返回，确保在动作范围内。\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            state = torch.FloatTensor(state[np.newaxis, :]).to(self.dvc)  # 1. 将状态转换为网络输入格式\n",
    "            a = self.actor(state).cpu().numpy()[0]  # 2. 获取动作\n",
    "\n",
    "            if deterministic:\n",
    "                return a  # 3. 返回动作（确定性策略）\n",
    "\n",
    "            else:\n",
    "                noise = np.random.normal(0, self.max_action * self.noise, size=self.action_dim)  # 4. 生成噪声\n",
    "                return (a + noise).clip(-self.max_action, self.max_action)  # 5. 添加噪声并确保在动作范围内\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        训练方法\n",
    "\n",
    "        说明:\n",
    "        1. 从经验回放缓冲区中采样一批数据，包括当前状态(s)、动作(a)、奖励(r)、下一个状态(s_next)和终止标志(dw)。\n",
    "        2. 使用目标策略网络(actor_target)预测下一个状态的动作(target_a_next)。\n",
    "        3. 使用目标评论网络(q_critic_target)计算目标Q值(target_Q)。\n",
    "        4. 计算目标Q值，考虑折扣因子(gamma)和终止标志(dw)。\n",
    "        5. 计算当前评论网络(q_critic)的Q值(current_Q)。\n",
    "        6. 计算Q值损失(q_loss)并执行评论网络优化。\n",
    "        7. 计算动作损失(a_loss)并执行策略网络优化。\n",
    "        8. 更新目标评论网络和目标策略网络参数，使用软更新策略。\n",
    "\n",
    "        注意:\n",
    "        - 该方法执行了一次深度强化学习的训练迭代。\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            s, a, r, s_next, dw = self.replay_buffer.sample(self.batch_size)  # 1. 采样经验数据\n",
    "            target_a_next = self.actor_target(s_next)  # 2. 预测下一个状态的动作\n",
    "            target_Q = self.q_critic_target(s_next, target_a_next)  # 3. 计算目标Q值\n",
    "            target_Q = r + (~dw) * self.gamma * target_Q  # 4. 计算目标Q值，考虑折扣因子和终止标志\n",
    "\n",
    "        current_Q = self.q_critic(s, a)  # 5. 计算当前评论网络的Q值\n",
    "\n",
    "        q_loss = F.mse_loss(current_Q, target_Q)  # 6. 计算Q值损失\n",
    "\n",
    "        self.q_critic_optimizer.zero_grad()\n",
    "        q_loss.backward()\n",
    "        self.q_critic_optimizer.step()  # 6. 执行评论网络优化\n",
    "\n",
    "        a_loss = -self.q_critic(s, self.actor(s)).mean()  # 7. 计算动作损失\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        a_loss.backward()\n",
    "        self.actor_optimizer.step()  # 7. 执行策略网络优化\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for param, target_param in zip(self.q_critic.parameters(), self.q_critic_target.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "            for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)  # 8. 更新目标网络参数，使用软更新策略\n",
    "        \n",
    "        return a_loss, q_loss\n",
    "\n",
    "    def save(self, episode):\n",
    "        \"\"\"\n",
    "        保存当前训练模型的Actor和Critic参数到文件\n",
    "\n",
    "        参数:\n",
    "        - episode: 当前训练的episode数，用于在文件名中标识不同的保存点\n",
    "        \"\"\"\n",
    "        model_path = f\"model/{cfg['path']}\"\n",
    "        # 检查是否存在'model'文件夹，如果不存在则创建\n",
    "        try:\n",
    "            os.makedirs(model_path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        # 保存Critic的参数到文件\n",
    "        torch.save(self.q_critic.state_dict(), f\"{model_path}/ddpg_critic{episode}.pth\")\n",
    "        # 保存Actor的参数到文件\n",
    "        torch.save(self.actor.state_dict(), f\"{model_path}/ppo_actor{episode}.pth\")\n",
    "\n",
    "    def load(self, episode):\n",
    "        \"\"\"\n",
    "        从文件加载之前保存的Actor和Critic参数\n",
    "\n",
    "        参数:\n",
    "        - episode: 要加载的保存点的episode数\n",
    "        \"\"\"\n",
    "        model_path = f\"model/{cfg['path']}\"\n",
    "        # 加载之前保存的Critic的参数\n",
    "        self.q_critic.load_state_dict(torch.load(f\"{model_path}/ddpg_critic{episode}.pth\"))\n",
    "        # 加载之前保存的Actor的参数\n",
    "        self.actor.load_state_dict(torch.load(f\"{model_path}/ppo_actor{episode}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_agent_config(cfg, path):\n",
    "    \"\"\"\n",
    "    配置环境和代理\n",
    "\n",
    "    参数:\n",
    "    - cfg: 包含配置信息的字典\n",
    "    - path: 模型保存路径\n",
    "\n",
    "    返回:\n",
    "    - env: Gym 环境\n",
    "    - agent: PPO 代理\n",
    "\n",
    "    说明:\n",
    "    1. 创建指定环境并设置渲染模式。\n",
    "    2. 如果配置中设置了种子，则为环境设置种子。\n",
    "    3. 获取环境的状态空间维度和动作空间维度。\n",
    "    4. 更新配置字典中的状态维度和动作维度。\n",
    "    5. 创建 PPO 代理。\n",
    "\n",
    "    注意:\n",
    "    - PPO 代理的创建依赖于配置信息和模型保存路径。\n",
    "    \"\"\"\n",
    "    env = gym.make(cfg['env_name'], render_mode=cfg['render_mode'])  # 1. 创建环境\n",
    "    eval_env = gym.make(cfg['env_name'], render_mode=cfg['render_mode'])\n",
    "    if cfg['seed'] != 0:\n",
    "        all_seed(env, seed=cfg['seed'])  # 2. 如果配置中设置了种子，则为环境设置种子\n",
    "\n",
    "    n_states = env.observation_space.shape[0]  # 3. 获取状态空间维度\n",
    "    n_actions = env.action_space.shape[0]  # 获取动作空间维度\n",
    "    max_action = float(env.action_space.high[0]) # 获取动作空间的最大值\n",
    "    max_e_steps = env._max_episode_steps  # 最大步数\n",
    "    print(f\"状态空间维度：{n_states}，动作空间维度：{n_actions}，最大步数：{max_e_steps}\")\n",
    "    cfg.update({\"state_dim\": n_states, \"action_dim\": n_actions, \"max_e_steps\": max_e_steps, \"max_action\": max_action})  # 4. 更新n_states和n_actions到cfg参数中\n",
    "\n",
    "    agent = DDPG_agent(cfg)  # 5. 创建 PPO 代理\n",
    "    return env, eval_env, agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "状态空间维度：11，动作空间维度：1，最大步数：1000\n",
      "超参数\n",
      "================================================================================\n",
      "        Name        \t       Value        \t        Type        \n",
      "     algo_name      \t        DDPO        \t   <class 'str'>    \n",
      "        dvc         \t        cuda        \t   <class 'str'>    \n",
      "      env_name      \tInvertedDoublePendulum-v4\t   <class 'str'>    \n",
      "    render_mode     \t     rgb_array      \t   <class 'str'>    \n",
      "       write        \t         1          \t   <class 'bool'>   \n",
      "       render       \t         0          \t   <class 'bool'>   \n",
      "     Loadmodel      \t         0          \t   <class 'bool'>   \n",
      "     ModelIdex      \t      2350000       \t   <class 'int'>    \n",
      "    deque_maxlen    \t         20         \t   <class 'int'>    \n",
      "        seed        \t         1          \t   <class 'int'>    \n",
      "  Max_train_steps   \t     50000000.0     \t  <class 'float'>   \n",
      "   save_interval    \t      50000.0       \t  <class 'float'>   \n",
      "   eval_interval    \t       2000.0       \t  <class 'float'>   \n",
      "   test_interval    \t      50000.0       \t  <class 'float'>   \n",
      "       gamma        \t        0.99        \t  <class 'float'>   \n",
      "     net_width      \t        256         \t   <class 'int'>    \n",
      "        a_lr        \t       0.001        \t  <class 'float'>   \n",
      "        c_lr        \t       0.001        \t  <class 'float'>   \n",
      "     batch_size     \t        128         \t   <class 'int'>    \n",
      "    random_steps    \t      50000.0       \t  <class 'float'>   \n",
      "       noise        \t        0.1         \t  <class 'float'>   \n",
      "        tau         \t       0.005        \t  <class 'float'>   \n",
      "        path        \tdevice:cuda/InvertedDoublePendulum-v4/seed:1/DDPO/net_width-256-gamma-0.99-a_lr-0.001-c_lr-0.001-batch_size-128\t   <class 'str'>    \n",
      "     state_dim      \t         11         \t   <class 'int'>    \n",
      "     action_dim     \t         1          \t   <class 'int'>    \n",
      "    max_e_steps     \t        1000        \t   <class 'int'>    \n",
      "     max_action     \t        1.0         \t  <class 'float'>   \n",
      "     mean_break     \t   100000000000.0   \t  <class 'float'>   \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "cfg = get_args()\n",
    "\n",
    "path = f\"device:{cfg['dvc']}/{cfg['env_name']}/seed:{cfg['seed']}/{cfg['algo_name']}/net_width-{cfg['net_width']}-gamma-{cfg['gamma']}-a_lr-{cfg['a_lr']}-c_lr-{cfg['c_lr']}-batch_size-{cfg['batch_size']}\"\n",
    "cfg.update({\"path\":path}) # 更新n_states和n_actions到cfg参数中\n",
    "\n",
    "base_dir = f\"log/{cfg['path']}\"\n",
    "\n",
    "env, eval_env, agent = env_agent_config(cfg, path)\n",
    "\n",
    "cfg.update({\"mean_break\":10e10})\n",
    "\n",
    "print_args(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg):\n",
    "    print(\"开始训练\")\n",
    "    env_seed = cfg['seed']\n",
    "    # 使用TensorBoard记录训练曲线\n",
    "    if cfg['write']:\n",
    "        writepath = 'runs/{}'.format(cfg['path']) # 构建TensorBoard日志路径\n",
    "        if os.path.exists(writepath): shutil.rmtree(writepath)  # 如果路径已存在，则删除该路径及其内容\n",
    "        writer = SummaryWriter(log_dir=writepath)  # 创建TensorBoard写入器，指定日志路径\n",
    "\n",
    "    # 如果指定了加载模型的选项，则加载模型\n",
    "    if cfg['Loadmodel']:\n",
    "        print(\"加载模型\")\n",
    "        agent.load(cfg['ModelIdex'])\n",
    "\n",
    "    # 如果选择渲染模式\n",
    "    if cfg['render']:\n",
    "        while True:\n",
    "            # 在环境中评估智能体的性能，并输出奖励\n",
    "            ep_r = evaluate_policy(env, agent, turns=1)\n",
    "            print('Env: ', cfg['env_name'],' Episode Reward: ', {ep_r})\n",
    "    else:\n",
    "        total_steps = 0\n",
    "        scores_deque = deque(maxlen=cfg['deque_maxlen'])\n",
    "\n",
    "        # 在达到最大训练步数前一直进行训练\n",
    "        while total_steps < cfg['Max_train_steps']:\n",
    "            # 重置环境，获取初始状态\n",
    "            s, info = env.reset(seed=env_seed)  # 重置环境，使用环境种子\n",
    "            env_seed += 1\n",
    "            done = False\n",
    "\n",
    "            # 与环境进行交互并训练\n",
    "            while not done:\n",
    "                if total_steps < cfg['random_steps']:\n",
    "                    a = env.action_space.sample()\n",
    "                else:\n",
    "                    a = agent.select_action(s, deterministic=False)\n",
    "                # 选择动作和动作对应的对数概率\n",
    "                s_next, r, dw, tr, info = env.step(a) # 与环境交互\n",
    "                done = (dw or tr)  # 如果游戏结束（死亡或胜利），则done为True\n",
    "\n",
    "                # 存储当前的转移数据\n",
    "                agent.replay_buffer.add(s, a, r, s_next, dw)\n",
    "                s = s_next\n",
    "                total_steps += 1\n",
    "\n",
    "                # 如果达到更新时间\n",
    "                if total_steps >= cfg['random_steps']:\n",
    "                    a_loss, c_loss = agent.train()  # 执行PPO算法的训练步骤\n",
    "                    if cfg['write']:\n",
    "                        writer.add_scalar('Loss_a', np.mean(a_loss.detach().cpu().numpy()), global_step=total_steps)\n",
    "                        writer.add_scalar('Loss_c', np.mean(c_loss.detach().cpu().numpy()), global_step=total_steps)\n",
    "\n",
    "                # 如果达到记录和日志的时间\n",
    "                if (total_steps % cfg['eval_interval'] == 0) and (total_steps >= cfg['random_steps']):\n",
    "                    # 在评估环境中评估智能体，并输出平均奖励\n",
    "                    score = evaluate_policy(eval_env, agent, turns=3, cfg=cfg)  # 对策略进行3次评估，取平均值\n",
    "                    scores_deque.append(score)\n",
    "                    if cfg['write']:\n",
    "                        writer.add_scalar('Score_ep', score, global_step=total_steps)  # 将评估得分记录到TensorBoard\n",
    "                        writer.add_scalar('Score_Average', np.mean(scores_deque), global_step=total_steps)\n",
    "                    print('EnvName:', cfg['env_name'], 'seed:', cfg['seed'],\n",
    "                          'steps: {}k'.format(int(total_steps / 1000)), 'score:', score)\n",
    "                    \n",
    "                if (total_steps % cfg['test_interval'] == 0) and (total_steps >= cfg['random_steps']):\n",
    "                    print(\"测试模型\")\n",
    "                    test_policy(eval_env, agent, total_steps, turns=1, path=cfg['path'], cfg=cfg)\n",
    "\n",
    "                # 如果达到保存模型的时间\n",
    "                if (total_steps % cfg['save_interval']  == 0) and (total_steps >= cfg['random_steps']):\n",
    "                    print(\"保存模型\")\n",
    "                    agent.save(total_steps)  # 保存模型\n",
    "\n",
    "                if (np.mean(scores_deque) >= cfg['mean_break']) and (len(scores_deque) >= cfg['deque_maxlen']):\n",
    "                    print('Environment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(total_steps, np.mean(scores_deque)))\n",
    "                    test_policy(eval_env, agent, total_steps, turns=1, path=cfg['path'], cfg=cfg)\n",
    "                    print(\"保存模型\")\n",
    "                    agent.save(total_steps)\n",
    "                    env.close()\n",
    "                    eval_env.close()\n",
    "                    return\n",
    "\n",
    "        env.close()\n",
    "        eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q1001p/anaconda3/envs/DRL_3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/q1001p/anaconda3/envs/DRL_3.11/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 50k score: 29\n",
      "测试模型\n",
      "保存视频\n",
      "保存模型\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 52k score: 98\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 54k score: 113\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 56k score: 156\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 58k score: 162\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 60k score: 168\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 62k score: 197\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 64k score: 212\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 66k score: 190\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 68k score: 135\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 70k score: 268\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 72k score: 141\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 74k score: 184\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 76k score: 244\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 78k score: 193\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 80k score: 228\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 82k score: 312\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 84k score: 243\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 86k score: 191\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 88k score: 228\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 90k score: 110\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 92k score: 330\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 94k score: 389\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 96k score: 259\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 98k score: 134\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 100k score: 268\n",
      "测试模型\n",
      "保存视频\n",
      "保存模型\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 102k score: 140\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 104k score: 211\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 106k score: 97\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 108k score: 131\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 110k score: 190\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 112k score: 212\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 114k score: 274\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 116k score: 88\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 118k score: 169\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 120k score: 162\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 122k score: 147\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 124k score: 113\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 126k score: 85\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 128k score: 191\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 130k score: 98\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 132k score: 271\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 134k score: 106\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 136k score: 94\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 138k score: 143\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 140k score: 91\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 142k score: 100\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 144k score: 265\n",
      "EnvName: InvertedDoublePendulum-v4 seed: 1 steps: 146k score: 203\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 如果达到更新时间\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_steps\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 49\u001b[0m     a_loss, c_loss \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 执行PPO算法的训练步骤\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     51\u001b[0m         writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss_a\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(a_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()), global_step\u001b[38;5;241m=\u001b[39mtotal_steps)\n",
      "Cell \u001b[0;32mIn[5], line 63\u001b[0m, in \u001b[0;36mDDPG_agent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m     s, a, r, s_next, dw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)  \u001b[38;5;66;03m# 1. 采样经验数据\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     target_a_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_target(s_next)  \u001b[38;5;66;03m# 2. 预测下一个状态的动作\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     target_Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_critic_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_next\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_a_next\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 3. 计算目标Q值\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     target_Q \u001b[38;5;241m=\u001b[39m r \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m~\u001b[39mdw) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m target_Q  \u001b[38;5;66;03m# 4. 计算目标Q值，考虑折扣因子和终止标志\u001b[39;00m\n\u001b[1;32m     66\u001b[0m current_Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_critic(s, a)  \u001b[38;5;66;03m# 5. 计算当前评论网络的Q值\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DRL_3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DRL_3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Python/DRL/PG/DDPG/utils.py:107\u001b[0m, in \u001b[0;36mQ_Critic.forward\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    105\u001b[0m sa \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([state, action], \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 将状态和动作连接在一起\u001b[39;00m\n\u001b[1;32m    106\u001b[0m q \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1(sa))  \u001b[38;5;66;03m# 第一个激活函数\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m q \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# 第二个激活函数\u001b[39;00m\n\u001b[1;32m    108\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml3(q)  \u001b[38;5;66;03m# 输出 Q 值\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q\n",
      "File \u001b[0;32m~/anaconda3/envs/DRL_3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DRL_3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DRL_3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
